#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIæ¨¡å‹è°ƒç”¨è„šæœ¬
æ”¯æŒæ–­ç‚¹ç»­ä¼ ã€è¿›åº¦æ˜¾ç¤ºå’Œé…ç½®åŒ–ç®¡ç†
æ”¯æŒæ–‡æœ¬å’Œå›¾ç‰‡è¾“å…¥ï¼ˆå…¼å®¹è§†è§‰æ¨¡å‹ï¼‰
æ”¯æŒå¤šProviderå’Œå¤šç§APIè°ƒç”¨æ–¹å¼
"""

import pandas as pd
import requests
import json
import yaml
import time
import os
import sys
import base64
import mimetypes
from typing import Dict, Any, Optional, Tuple, List, Union
from tqdm import tqdm
import argparse
import logging
from datetime import datetime
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock


class AIModelProcessor:
    def __init__(self, config_file: str = "config.yaml", providers_file: str = "providers.yaml"):
        """åˆå§‹åŒ–AIæ¨¡å‹å¤„ç†å™¨"""
        self.config = self.load_config(config_file)
        self.providers = self.load_providers(providers_file)
        self.provider_config = self.get_provider_config()
        self.setup_logging()
        self.csv_lock = Lock()  # CSVæ–‡ä»¶å†™å…¥é”
        
    def load_config(self, config_file: str) -> Dict[str, Any]:
        """åŠ è½½è¿è¡Œé…ç½®æ–‡ä»¶"""
        default_config = {
            "provider": "openai",
            "model_name": "gpt-4o",
            "temperature": 0.6,
            "max_tokens": 2000,
            "csv_input_file": "sample_data.csv",
            "prompt_file": "system_prompt.md",
            "user_prompt_column": "user_prompt",
            "image_column": "",
            "image_base_path": "",
            "image_detail": "auto",
            "max_workers": 3,
            "request_delay": 0.5
        }

        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                user_config = yaml.safe_load(f)
                default_config.update(user_config)
        else:
            with open(config_file, 'w', encoding='utf-8') as f:
                yaml.dump(default_config, f, allow_unicode=True, default_flow_style=False)
            print(f"ğŸ“ å·²åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: {config_file}")

        return default_config
    
    def load_providers(self, providers_file: str) -> Dict[str, Any]:
        """åŠ è½½Provideré…ç½®æ–‡ä»¶"""
        default_providers = {
            "providers": {
                "openai": {
                    "api_url": "https://api.openai.com/v1/chat/completions",
                    "api_key": "",
                    "api_type": "openai",
                    "timeout": 60,
                    "max_retries": 3,
                    "retry_delay": 2
                }
            },
            "default_provider": "openai"
        }

        if os.path.exists(providers_file):
            with open(providers_file, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        else:
            with open(providers_file, 'w', encoding='utf-8') as f:
                yaml.dump(default_providers, f, allow_unicode=True, default_flow_style=False)
            print(f"ğŸ“ å·²åˆ›å»ºé»˜è®¤Provideré…ç½®æ–‡ä»¶: {providers_file}")
            return default_providers
    
    def get_provider_config(self) -> Dict[str, Any]:
        """è·å–å½“å‰Providerçš„é…ç½®"""
        provider_name = self.config.get("provider", self.providers.get("default_provider", "openai"))
        providers = self.providers.get("providers", {})
        
        if provider_name not in providers:
            print(f"âŒ Provider '{provider_name}' ä¸å­˜åœ¨äº providers.yaml")
            print(f"å¯ç”¨çš„Provider: {', '.join(providers.keys())}")
            sys.exit(1)
        
        return providers[provider_name]
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        file_handler = logging.FileHandler('ai_processor.log', encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
        
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)
        console_handler.setFormatter(logging.Formatter('%(message)s'))
        
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.INFO)
        # é¿å…é‡å¤æ·»åŠ handler
        if not self.logger.handlers:
            self.logger.addHandler(file_handler)
            self.logger.addHandler(console_handler)
        
        logging.getLogger('urllib3').setLevel(logging.WARNING)
        logging.getLogger('requests').setLevel(logging.WARNING)
    
    def load_system_prompt(self) -> str:
        """åŠ è½½ç³»ç»Ÿæç¤ºè¯"""
        prompt_file = self.config["prompt_file"]
        if not os.path.exists(prompt_file):
            self.logger.error(f"âŒ æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {prompt_file}")
            return ""
        
        with open(prompt_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        if 'system_prompt = """' in content:
            start = content.find('system_prompt = """') + len('system_prompt = """')
            end = content.rfind('"""')
            if end > start:
                content = content[start:end]
        
        return content.strip()
    
    def check_row_processed(self, df: pd.DataFrame, index: int, reasoning_col: str, classification_col: str) -> bool:
        """æ£€æŸ¥æŒ‡å®šè¡Œæ˜¯å¦å·²ç»å¤„ç†è¿‡"""
        if reasoning_col not in df.columns or classification_col not in df.columns:
            return False
        
        reasoning = df.at[index, reasoning_col]
        classification = df.at[index, classification_col]
        
        return (not pd.isna(reasoning) and str(reasoning).strip() != "" and
                not pd.isna(classification) and str(classification).strip() != "")
    
    def encode_image_to_base64(self, image_path: str) -> Optional[str]:
        """å°†æœ¬åœ°å›¾ç‰‡è½¬æ¢ä¸ºBase64ç¼–ç çš„data URL"""
        if not os.path.exists(image_path):
            self.logger.error(f"âŒ å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
            return None
        
        mime_type, _ = mimetypes.guess_type(image_path)
        supported_types = ['image/jpeg', 'image/png', 'image/gif', 'image/webp']
        
        if mime_type not in supported_types:
            self.logger.error(f"âŒ ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼: {mime_type}")
            return None
        
        try:
            with open(image_path, 'rb') as f:
                image_data = base64.b64encode(f.read()).decode('utf-8')
            return f"data:{mime_type};base64,{image_data}"
        except Exception as e:
            self.logger.error(f"âŒ è¯»å–å›¾ç‰‡å¤±è´¥: {str(e)}")
            return None
    
    def get_image_base64_raw(self, image_path: str) -> Optional[Tuple[str, str]]:
        """è·å–å›¾ç‰‡çš„åŸå§‹Base64æ•°æ®å’ŒMIMEç±»å‹"""
        if not os.path.exists(image_path):
            return None
        
        mime_type, _ = mimetypes.guess_type(image_path)
        if not mime_type:
            return None
        
        try:
            with open(image_path, 'rb') as f:
                image_data = base64.b64encode(f.read()).decode('utf-8')
            return image_data, mime_type
        except:
            return None
    
    def build_user_message_openai(self, text: str, image_path: str = None) -> Union[str, List]:
        """æ„å»ºOpenAIæ ¼å¼çš„ç”¨æˆ·æ¶ˆæ¯"""
        if not image_path:
            return text
        
        image_base_path = self.config.get("image_base_path", "")
        if image_base_path and not os.path.isabs(image_path):
            image_path = os.path.join(image_base_path, image_path)
        
        image_url = self.encode_image_to_base64(image_path)
        if not image_url:
            return text
        
        content = []
        if text and text.strip():
            content.append({"type": "text", "text": text})
        
        content.append({
            "type": "image_url",
            "image_url": {
                "url": image_url,
                "detail": self.config.get("image_detail", "auto")
            }
        })
        
        return content
    
    def build_user_message_anthropic(self, text: str, image_path: str = None) -> List:
        """æ„å»ºAnthropicæ ¼å¼çš„ç”¨æˆ·æ¶ˆæ¯"""
        content = []
        
        if image_path:
            image_base_path = self.config.get("image_base_path", "")
            if image_base_path and not os.path.isabs(image_path):
                image_path = os.path.join(image_base_path, image_path)
            
            result = self.get_image_base64_raw(image_path)
            if result:
                image_data, mime_type = result
                content.append({
                    "type": "image",
                    "source": {
                        "type": "base64",
                        "media_type": mime_type,
                        "data": image_data
                    }
                })
        
        if text and text.strip():
            content.append({"type": "text", "text": text})
        
        return content if content else [{"type": "text", "text": text or ""}]
    
    def call_api_openai(self, user_prompt: str, system_prompt: str, image_path: str = None) -> Optional[str]:
        """è°ƒç”¨OpenAIå…¼å®¹æ ¼å¼çš„API"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.provider_config['api_key']}"
        }
        
        user_content = self.build_user_message_openai(user_prompt, image_path)
        
        data = {
            "model": self.config["model_name"],
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            "temperature": self.config.get("temperature", 0.6)
        }
        
        if "max_tokens" in self.config:
            data["max_tokens"] = self.config["max_tokens"]
        
        max_retries = self.provider_config.get("max_retries", 3)
        retry_delay = self.provider_config.get("retry_delay", 1)
        
        for attempt in range(max_retries):
            try:
                response = requests.post(
                    self.provider_config["api_url"],
                    headers=headers,
                    json=data,
                    timeout=self.provider_config.get("timeout", 60)
                )
                
                if response.status_code == 200:
                    result = response.json()
                    if "choices" in result and len(result["choices"]) > 0:
                        return result["choices"][0]["message"]["content"]
                else:
                    self.logger.error(f"âŒ APIè°ƒç”¨å¤±è´¥ (çŠ¶æ€ç : {response.status_code})")
                
            except requests.exceptions.RequestException as e:
                if attempt == max_retries - 1:
                    self.logger.error(f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)[:50]}...")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay * (attempt + 1))
        
        return None
    
    def call_api_anthropic(self, user_prompt: str, system_prompt: str, image_path: str = None) -> Optional[str]:
        """è°ƒç”¨Anthropic Claude API"""
        headers = {
            "Content-Type": "application/json",
            "x-api-key": self.provider_config['api_key'],
            "anthropic-version": self.provider_config.get("api_version", "2023-06-01")
        }
        
        user_content = self.build_user_message_anthropic(user_prompt, image_path)
        
        data = {
            "model": self.config["model_name"],
            "max_tokens": self.config.get("max_tokens", 4096),
            "system": system_prompt,
            "messages": [
                {"role": "user", "content": user_content}
            ]
        }
        
        if "temperature" in self.config:
            data["temperature"] = self.config["temperature"]
        
        max_retries = self.provider_config.get("max_retries", 3)
        retry_delay = self.provider_config.get("retry_delay", 2)
        
        for attempt in range(max_retries):
            try:
                response = requests.post(
                    self.provider_config["api_url"],
                    headers=headers,
                    json=data,
                    timeout=self.provider_config.get("timeout", 60)
                )
                
                if response.status_code == 200:
                    result = response.json()
                    if "content" in result and len(result["content"]) > 0:
                        return result["content"][0]["text"]
                else:
                    self.logger.error(f"âŒ APIè°ƒç”¨å¤±è´¥ (çŠ¶æ€ç : {response.status_code})")
                
            except requests.exceptions.RequestException as e:
                if attempt == max_retries - 1:
                    self.logger.error(f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)[:50]}...")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay * (attempt + 1))
        
        return None
    
    def call_api_google(self, user_prompt: str, system_prompt: str, image_path: str = None) -> Optional[str]:
        """è°ƒç”¨Google Gemini API"""
        model_name = self.config["model_name"]
        api_key = self.provider_config['api_key']
        base_url = self.provider_config["api_url"]
        url = f"{base_url}/models/{model_name}:generateContent?key={api_key}"
        
        headers = {"Content-Type": "application/json"}
        
        # æ„å»ºå†…å®¹
        parts = []
        
        # æ·»åŠ ç³»ç»Ÿæç¤ºè¯ä½œä¸ºæ–‡æœ¬çš„ä¸€éƒ¨åˆ†
        if system_prompt:
            parts.append({"text": f"System: {system_prompt}\n\nUser: {user_prompt}"})
        else:
            parts.append({"text": user_prompt})
        
        # æ·»åŠ å›¾ç‰‡
        if image_path:
            image_base_path = self.config.get("image_base_path", "")
            if image_base_path and not os.path.isabs(image_path):
                image_path = os.path.join(image_base_path, image_path)
            
            result = self.get_image_base64_raw(image_path)
            if result:
                image_data, mime_type = result
                parts.append({
                    "inline_data": {
                        "mime_type": mime_type,
                        "data": image_data
                    }
                })
        
        data = {
            "contents": [{"parts": parts}],
            "generationConfig": {
                "temperature": self.config.get("temperature", 0.6),
                "maxOutputTokens": self.config.get("max_tokens", 2048)
            }
        }
        
        max_retries = self.provider_config.get("max_retries", 3)
        retry_delay = self.provider_config.get("retry_delay", 2)
        
        for attempt in range(max_retries):
            try:
                response = requests.post(
                    url,
                    headers=headers,
                    json=data,
                    timeout=self.provider_config.get("timeout", 60)
                )
                
                if response.status_code == 200:
                    result = response.json()
                    if "candidates" in result and len(result["candidates"]) > 0:
                        candidate = result["candidates"][0]
                        if "content" in candidate and "parts" in candidate["content"]:
                            return candidate["content"]["parts"][0]["text"]
                else:
                    self.logger.error(f"âŒ APIè°ƒç”¨å¤±è´¥ (çŠ¶æ€ç : {response.status_code})")
                
            except requests.exceptions.RequestException as e:
                if attempt == max_retries - 1:
                    self.logger.error(f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)[:50]}...")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay * (attempt + 1))
        
        return None
    
    def call_ai_api(self, user_prompt: str, system_prompt: str, image_path: str = None) -> Optional[Dict[str, Any]]:
        """ç»Ÿä¸€çš„APIè°ƒç”¨å…¥å£ï¼Œæ ¹æ®api_typeé€‰æ‹©è°ƒç”¨æ–¹å¼"""
        api_type = self.provider_config.get("api_type", "openai")
        
        if api_type == "openai":
            content = self.call_api_openai(user_prompt, system_prompt, image_path)
        elif api_type == "anthropic":
            content = self.call_api_anthropic(user_prompt, system_prompt, image_path)
        elif api_type == "google":
            content = self.call_api_google(user_prompt, system_prompt, image_path)
        else:
            self.logger.error(f"âŒ ä¸æ”¯æŒçš„APIç±»å‹: {api_type}")
            return None
        
        if content:
            return self.parse_ai_response(content)
        return None
    
    def parse_ai_response(self, content: str) -> Optional[Dict[str, Any]]:
        """è§£æAIè¿”å›çš„JSONå†…å®¹"""
        try:
            if content.strip().startswith('{') and content.strip().endswith('}'):
                return json.loads(content)
            
            if '```json' in content:
                start = content.find('```json') + 7
                end = content.find('```', start)
                if end > start:
                    json_content = content[start:end].strip()
                    return json.loads(json_content)
            
            start = content.find('{')
            end = content.rfind('}') + 1
            if start >= 0 and end > start:
                json_content = content[start:end]
                return json.loads(json_content)
            
            self.logger.error(f"âŒ æ— æ³•è§£æAIå“åº”ä¸ºJSON")
            return None
            
        except json.JSONDecodeError as e:
            self.logger.error(f"âŒ JSONè§£æé”™è¯¯: {str(e)[:30]}...")
            return None
    
    def process_single_row(self, index: int, user_prompt: str, system_prompt: str, 
                          df: pd.DataFrame, reasoning_col: str, classification_col: str,
                          image_path: str = None) -> bool:
        """å¤„ç†å•è¡Œæ•°æ®ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        try:
            time.sleep(self.config.get("request_delay", 0.5))
            
            result = self.call_ai_api(user_prompt, system_prompt, image_path)
            
            if result:
                reasoning = result.get("Thoughts", "")
                classification = result.get("Category", "")
                
                with self.csv_lock:
                    df.at[index, reasoning_col] = reasoning
                    df.at[index, classification_col] = classification
                
                return True
            else:
                return False
                
        except Exception as e:
            return False
    
    def process_csv(self) -> bool:
        """å¤„ç†CSVæ–‡ä»¶"""
        csv_file = self.config["csv_input_file"]
        
        if not os.path.exists(csv_file):
            self.logger.error(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
            return False
        
        df = pd.read_csv(csv_file)
        user_prompt_col = self.config["user_prompt_column"]
        
        if user_prompt_col not in df.columns:
            self.logger.error(f"âŒ CSVæ–‡ä»¶ä¸­ä¸å­˜åœ¨åˆ—: {user_prompt_col}")
            return False
        
        # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„Providerå’Œæ¨¡å‹
        provider_name = self.config.get("provider", "unknown")
        model_name = self.config.get("model_name", "unknown")
        api_type = self.provider_config.get("api_type", "unknown")
        self.logger.info(f"ğŸ¤– Provider: {provider_name} | æ¨¡å‹: {model_name} | APIç±»å‹: {api_type}")
        
        image_col = self.config.get("image_column", "")
        has_image_col = image_col and image_col in df.columns
        
        if image_col and image_col not in df.columns:
            self.logger.warning(f"âš ï¸ é…ç½®çš„å›¾ç‰‡åˆ— '{image_col}' ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨çº¯æ–‡æœ¬æ¨¡å¼")
            has_image_col = False
        
        if has_image_col:
            self.logger.info(f"ğŸ–¼ï¸ å·²å¯ç”¨å›¾ç‰‡æ¨¡å¼ï¼Œå›¾ç‰‡åˆ—: {image_col}")
        
        system_prompt = self.load_system_prompt()
        if not system_prompt:
            self.logger.error("âŒ æ— æ³•åŠ è½½ç³»ç»Ÿæç¤ºè¯")
            return False
        
        model_name_safe = self.config["model_name"].replace("-", "_").replace(".", "_")
        reasoning_col = f"reasoning_{model_name_safe}"
        classification_col = f"classification_{model_name_safe}"
        
        if reasoning_col not in df.columns:
            df[reasoning_col] = ""
        if classification_col not in df.columns:
            df[classification_col] = ""
        
        total_rows = len(df)
        rows_to_process = []
        processed_count = 0
        
        self.logger.info(f"ğŸ“Š æ‰«æCSVæ–‡ä»¶ï¼Œæ£€æŸ¥å¤„ç†çŠ¶æ€...")
        
        for index, row in df.iterrows():
            if self.check_row_processed(df, index, reasoning_col, classification_col):
                processed_count += 1
                continue
            
            user_prompt = str(row[user_prompt_col])
            
            image_path = None
            if has_image_col:
                img = row.get(image_col, "")
                if pd.notna(img) and str(img).strip():
                    image_path = str(img).strip()
            
            rows_to_process.append((index, user_prompt, image_path))
        
        self.logger.info(f"ğŸ“ˆ æ‰«æå®Œæˆ: æ€»è®¡ {total_rows} è¡Œï¼Œå·²å¤„ç† {processed_count} è¡Œï¼Œå¾…å¤„ç† {len(rows_to_process)} è¡Œ")
        
        if not rows_to_process:
            self.logger.info("âœ… æ‰€æœ‰æ•°æ®å·²å¤„ç†å®Œæˆ")
            return True
        
        self.logger.info(f"ğŸš€ å¼€å§‹å¤„ç† {len(rows_to_process)} æ¡æ•°æ® (çº¿ç¨‹æ•°: {self.config['max_workers']})")
        
        new_processed_count = 0
        max_workers = self.config.get("max_workers", 3)
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            with tqdm(total=len(rows_to_process), desc="ğŸ“Š å¤„ç†è¿›åº¦", 
                     bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]",
                     ncols=80) as pbar:
                future_to_index = {}
                for index, user_prompt, image_path in rows_to_process:
                    future = executor.submit(
                        self.process_single_row, 
                        index, user_prompt, system_prompt, 
                        df, reasoning_col, classification_col,
                        image_path
                    )
                    future_to_index[future] = index
                
                for future in as_completed(future_to_index):
                    index = future_to_index[future]
                    try:
                        success = future.result()
                        if success:
                            new_processed_count += 1
                        
                        if new_processed_count % 10 == 0:
                            with self.csv_lock:
                                df.to_csv(csv_file, index=False)
                                
                        pbar.update(1)
                        
                    except Exception as e:
                        pbar.update(1)
        
        with self.csv_lock:
            df.to_csv(csv_file, index=False)
        
        self.logger.info(f"ğŸ‰ å¤„ç†å®Œæˆï¼å…±å¤„ç† {new_processed_count} æ¡æ–°æ•°æ®")
        return True
    
    def reset_progress(self):
        """é‡ç½®è¿›åº¦"""
        csv_file = self.config["csv_input_file"]
        if not os.path.exists(csv_file):
            self.logger.error(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
            return
        
        df = pd.read_csv(csv_file)
        model_name_safe = self.config["model_name"].replace("-", "_").replace(".", "_")
        reasoning_col = f"reasoning_{model_name_safe}"
        classification_col = f"classification_{model_name_safe}"
        
        if reasoning_col in df.columns:
            df[reasoning_col] = ""
        if classification_col in df.columns:
            df[classification_col] = ""
        
        df.to_csv(csv_file, index=False)
        self.logger.info("ğŸ”„ è¿›åº¦å·²é‡ç½®ï¼Œå·²æ¸…ç©ºæ‰€æœ‰å¤„ç†ç»“æœ")
    
    def show_status(self):
        """æ˜¾ç¤ºå½“å‰çŠ¶æ€"""
        csv_file = self.config["csv_input_file"]
        if not os.path.exists(csv_file):
            print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
            return
        
        df = pd.read_csv(csv_file)
        model_name_safe = self.config["model_name"].replace("-", "_").replace(".", "_")
        reasoning_col = f"reasoning_{model_name_safe}"
        classification_col = f"classification_{model_name_safe}"
        
        total_rows = len(df)
        processed_rows = 0
        
        for index in range(total_rows):
            if self.check_row_processed(df, index, reasoning_col, classification_col):
                processed_rows += 1
        
        progress_pct = processed_rows/total_rows*100 if total_rows > 0 else 0
        remaining = total_rows - processed_rows
        
        provider_name = self.config.get("provider", "unknown")
        model_name = self.config.get("model_name", "unknown")
        
        print(f"\nğŸ“Š å¤„ç†çŠ¶æ€")
        print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print(f"ğŸ¤– Provider:   {provider_name}")
        print(f"ğŸ“¦ æ¨¡å‹:       {model_name}")
        print(f"ğŸ“ æ€»è¡Œæ•°:     {total_rows:,}")
        print(f"âœ… å·²å¤„ç†:     {processed_rows:,}")
        print(f"â³ å¾…å¤„ç†:     {remaining:,}")
        print(f"ğŸ“ˆ å®Œæˆç‡:     {progress_pct:.1f}%")
        print(f"ğŸ”§ çº¿ç¨‹æ•°:     {self.config.get('max_workers', 3)}")
        
        bar_length = 30
        filled_length = int(bar_length * progress_pct / 100)
        bar = "â–ˆ" * filled_length + "â–‘" * (bar_length - filled_length)
        print(f"ğŸ“Š è¿›åº¦æ¡:     [{bar}] {progress_pct:.1f}%")
        
        if processed_rows > 0 and remaining > 0:
            avg_time_per_item = 3.0 / self.config.get('max_workers', 3)
            estimated_hours = (remaining * avg_time_per_item) / 3600
            if estimated_hours < 1:
                estimated_minutes = (remaining * avg_time_per_item) / 60
                print(f"â° é¢„ä¼°æ—¶é—´:   {estimated_minutes:.0f} åˆ†é’Ÿ")
            else:
                print(f"â° é¢„ä¼°æ—¶é—´:   {estimated_hours:.1f} å°æ—¶")
        print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")
    
    def list_providers(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„Provider"""
        providers = self.providers.get("providers", {})
        default_provider = self.providers.get("default_provider", "")
        
        print(f"\nğŸ“‹ å¯ç”¨çš„Provideråˆ—è¡¨")
        print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        
        for name, config in providers.items():
            is_default = " (é»˜è®¤)" if name == default_provider else ""
            api_type = config.get("api_type", "unknown")
            has_key = "âœ…" if config.get("api_key") else "âŒ"
            models = config.get("available_models", [])
            
            print(f"\nğŸ”¹ {name}{is_default}")
            print(f"   APIç±»å‹: {api_type}")
            print(f"   å¯†é’¥çŠ¶æ€: {has_key}")
            print(f"   å¯ç”¨æ¨¡å‹: {', '.join(models[:3])}{'...' if len(models) > 3 else ''}")
        
        print(f"\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")


def main():
    parser = argparse.ArgumentParser(description='AIæ¨¡å‹è°ƒç”¨è„šæœ¬ï¼ˆæ”¯æŒå¤šProviderï¼‰')
    parser.add_argument('--config', default='config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--providers', default='providers.yaml', help='Provideré…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--reset', action='store_true', help='é‡ç½®è¿›åº¦')
    parser.add_argument('--status', action='store_true', help='æ˜¾ç¤ºçŠ¶æ€')
    parser.add_argument('--list-providers', action='store_true', help='åˆ—å‡ºæ‰€æœ‰Provider')
    parser.add_argument('--workers', type=int, help='å¹¶å‘çº¿ç¨‹æ•°é‡')
    parser.add_argument('--provider', type=str, help='æŒ‡å®šä½¿ç”¨çš„Provider')
    parser.add_argument('--model', type=str, help='æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹')
    
    args = parser.parse_args()
    
    processor = AIModelProcessor(args.config, args.providers)
    
    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
    if args.workers is not None:
        processor.config["max_workers"] = args.workers
        print(f"ğŸ”§ ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„çº¿ç¨‹æ•°: {args.workers}")
    
    if args.provider is not None:
        processor.config["provider"] = args.provider
        processor.provider_config = processor.get_provider_config()
        print(f"ğŸ”§ ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„Provider: {args.provider}")
    
    if args.model is not None:
        processor.config["model_name"] = args.model
        print(f"ğŸ”§ ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„æ¨¡å‹: {args.model}")
    
    if args.list_providers:
        processor.list_providers()
        return
    
    if args.reset:
        processor.reset_progress()
        return
    
    if args.status:
        processor.show_status()
        return
    
    # æ£€æŸ¥APIå¯†é’¥
    if not processor.provider_config.get("api_key"):
        provider_name = processor.config.get("provider", "unknown")
        print(f"âš ï¸  è¯·åœ¨ providers.yaml ä¸­ä¸º '{provider_name}' è®¾ç½®APIå¯†é’¥")
        return
    
    processor.process_csv()


if __name__ == "__main__":
    main()
